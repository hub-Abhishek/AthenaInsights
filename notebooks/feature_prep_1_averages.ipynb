{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_prefix = 's3://'\n",
    "bucket = 'sisyphus-general-bucket'\n",
    "primary_folder = 'AthenaInsights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.list_objects_v2(\n",
    "    Bucket=bucket,\n",
    "    Prefix=f'{primary_folder}/data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "all_symbols = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def calculate_ma(df, ema=True, sma=True, all_windows=[x for x in range(1, 240)]):\n",
    "#     # Calculate EMAs and SMAs for each window\n",
    "#     combined_df = pd.DataFrame()\n",
    "#     for symbol in df.symbol.unique():\n",
    "#         current_df = df[df.symbol==symbol]\n",
    "#         print(symbol)\n",
    "#         for window in tqdm(all_windows):\n",
    "#             for price in ['open', 'high', 'low', 'close', 'volume']:\n",
    "#                 current_df[f'{price}_ema_{window}m'] = current_df[price].ewm(span=window, adjust=False).mean()\n",
    "#                 current_df[f'{price}_sma_{window}m'] = current_df[price].rolling(window=window).mean()\n",
    "#         combined_df = pd.concat([combined_df, current_df])\n",
    "#     df = combined_df\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for content in response.get('Contents', []):\n",
    "#     current_file_dict = {}\n",
    "#     current_file_dict['name'] = content['Key'].split('/')[-1].split('.')[0]\n",
    "#     current_file_dict['loc'] = f\"{s3_prefix}{bucket}/{content['Key']}\"\n",
    "#     df = pd.read_parquet(current_file_dict['loc'])\n",
    "#     print(current_file_dict['name'])\n",
    "#     # print(df.head(1))\n",
    "#     df = calculate_ma(df)\n",
    "#     df.to_parquet(f\"{s3_prefix}{bucket}/{primary_folder}/data/data_prep/{current_file_dict['name']}.parquet\")\n",
    "#     print(f\"saved to {s3_prefix}{bucket}/{primary_folder}/data/data_prep/{current_file_dict['name']}.parquet\")\n",
    "#     del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_windows = list(range(1, 240))\n",
    "\n",
    "def calculate_ma(df, ema=True, sma=True, all_windows=all_windows):\n",
    "    # Function to apply moving averages\n",
    "    def apply_moving_averages(group):\n",
    "        for window in tqdm(all_windows):\n",
    "            for price in ['open', 'high', 'low', 'close', 'volume']:\n",
    "                if ema:\n",
    "                    group[f'{price}_ema_{window}m'] = group[price].ewm(span=window, adjust=False).mean()\n",
    "                if sma:\n",
    "                    group[f'{price}_sma_{window}m'] = group[price].rolling(window=window).mean()\n",
    "        return group\n",
    "\n",
    "    # Apply function by group\n",
    "    return df.groupby('symbol').apply(apply_moving_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_120min.parquet',\n",
       " 's3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_15min.parquet',\n",
       " 's3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_180min.parquet',\n",
       " 's3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_20min.parquet',\n",
       " 's3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_240min.parquet',\n",
       " 's3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_25min.parquet',\n",
       " 's3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_30min.parquet',\n",
       " 's3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_60min.parquet']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for content in response.get('Contents', []):\n",
    "    # print(f\"{s3_prefix}{bucket}/{content['Key']}\")\n",
    "    paths.append(f\"{s3_prefix}{bucket}/{content['Key']}\")\n",
    "\n",
    "current_run_paths = [x for x in paths if '240min' in x or '180min' in x or '120min' in x or '60min' in x]\n",
    "# current_run_paths = [x for x in paths if '30min' in x or '25min' in x or '_20min' in x or '15min' in x or '10min' in x]\n",
    "current_run_paths = [x for x in paths if '_1min' in x]\n",
    "current_run_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_100D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 80.84it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 85.28it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 89.39it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 88.39it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 94.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_10D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 106.46it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 78.96it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 100.58it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 97.05it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 85.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_150D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 87.49it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 92.54it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 100.04it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 90.59it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 81.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_15D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 102.72it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 59.08it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 78.54it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 78.37it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 111.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_1D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 95.12it/s] \n",
      "100%|██████████| 239/239 [00:03<00:00, 75.82it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 73.80it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 87.16it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 88.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_200D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:03<00:00, 67.38it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 64.53it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 79.54it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 89.00it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 103.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_20D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 94.44it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 85.69it/s] \n",
      "100%|██████████| 239/239 [00:03<00:00, 78.03it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 69.11it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 94.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_2D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 83.95it/s]\n",
      "100%|██████████| 239/239 [00:01<00:00, 121.80it/s]\n",
      "100%|██████████| 239/239 [00:01<00:00, 125.84it/s]\n",
      "100%|██████████| 239/239 [00:01<00:00, 124.11it/s]\n",
      "100%|██████████| 239/239 [00:01<00:00, 124.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_30D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 92.51it/s] \n",
      "100%|██████████| 239/239 [00:03<00:00, 77.11it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 114.82it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 113.30it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 96.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_3D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 91.73it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 109.08it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 83.30it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 103.54it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 117.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_50D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 90.28it/s] \n",
      "100%|██████████| 239/239 [00:03<00:00, 70.85it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 98.83it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 103.10it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 90.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sisyphus-general-bucket/AthenaInsights/data/processed/stock_bars_5D.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:02<00:00, 87.71it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 89.27it/s] \n",
      "100%|██████████| 239/239 [00:02<00:00, 86.14it/s] \n",
      "100%|██████████| 239/239 [00:03<00:00, 77.93it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 79.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for content in current_run_paths:\n",
    "    df = pd.read_parquet(content)\n",
    "    print(content)\n",
    "    df = calculate_ma(df)\n",
    "    df.to_parquet(content.replace('processed', 'data_prep'))\n",
    "    # df.to_parquet(f\"{s3_prefix}{bucket}/{primary_folder}/data/data_prep/{current_file_dict['name']}.parquet\")\n",
    "    # print(f\"saved to {s3_prefix}{bucket}/{primary_folder}/data/data_prep/{current_file_dict['name']}.parquet\")\n",
    "    # print(content.replace('processed', 'data_prep'))\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3min, 5min, \n",
    "\n",
    "# all_windows = list(range(1, 240))\n",
    "\n",
    "# def calculate_ma(df, ema=True, sma=True, all_windows=all_windows, price='open'):\n",
    "#     # Function to apply moving averages\n",
    "#     def apply_moving_averages(group):\n",
    "#         for window in tqdm(all_windows):\n",
    "#             if ema:\n",
    "#                 group[f'{price}_ema_{window}m'] = group[price].ewm(span=window, adjust=False).mean()\n",
    "#             if sma:\n",
    "#                 group[f'{price}_sma_{window}m'] = group[price].rolling(window=window).mean()\n",
    "#         return group\n",
    "\n",
    "#     # Apply function by group\n",
    "#     return df.groupby('symbol').apply(apply_moving_averages)\n",
    "\n",
    "# for content in current_run_paths:\n",
    "#     for price in ['open', 'high', 'low', 'close', 'volume']:\n",
    "#         df = pd.read_parquet(content)\n",
    "#         print(content)\n",
    "#         # print(df.head(1))\n",
    "#         df = calculate_ma(df[[price, 'symbol']], price='open')\n",
    "#         df.to_parquet(content.replace('processed', 'data_prep').replace('.parquet', f'_{price}.parquet'))\n",
    "#         print(f\"saved to {content.replace('processed', 'data_prep').replace('.parquet', f'_{price}.parquet')}\")\n",
    "#         # df.to_parquet(f\"{s3_prefix}{bucket}/{primary_folder}/data/data_prep/{current_file_dict['name']}.parquet\")\n",
    "#         # print(f\"saved to {s3_prefix}{bucket}/{primary_folder}/data/data_prep/{current_file_dict['name']}.parquet\")\n",
    "#         # print(content.replace('processed', 'data_prep'))\n",
    "#         del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1min, 2min\n",
    "\n",
    "# all_windows = list(range(1, 240))\n",
    "\n",
    "# def calculate_ma_for_year(df, year, ema=True, sma=True, all_windows=all_windows):\n",
    "#     # Filter data for the specified year including last three days of previous year\n",
    "#     start_date = pd.Timestamp(year=year, month=1, day=1, tz='US/Eastern') - pd.Timedelta(days=3)\n",
    "#     end_date = pd.Timestamp(year=year, month=12, day=31, tz='US/Eastern')\n",
    "#     # print(df.head())\n",
    "#     year_data = df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "\n",
    "\n",
    "#     def apply_moving_averages(group):\n",
    "#         # print(group)\n",
    "#         for window in tqdm(all_windows):\n",
    "#             if ema:\n",
    "#                 group[f'{price}_ema_{window}m'] = group[price].ewm(span=window, adjust=False).mean()\n",
    "#             if sma:\n",
    "#                 group[f'{price}_sma_{window}m'] = group[price].rolling(window=window).mean()\n",
    "#         return group\n",
    "\n",
    "#     # Apply moving averages\n",
    "#     return year_data.groupby('symbol').apply(apply_moving_averages)#.reset_index()#.set_index('us_eastern_timestamp')\n",
    "\n",
    "# for content in current_run_paths:\n",
    "#     # Process each price\n",
    "#     for price in ['open', 'high', 'low', 'close', 'volume']:\n",
    "#         for year in range(2020, 2024):  # Update as needed\n",
    "#             # df_price = .copy()  # focus on one price at a time\n",
    "#             df = pd.read_parquet(content)[[price, 'symbol']].ffill()\n",
    "#             df = calculate_ma_for_year(df, year)\n",
    "#             df.to_parquet(content.replace('processed', 'data_prep').replace('.parquet', f'_{price}_{year}.parquet'))\n",
    "#             print(content.replace('processed', 'data_prep').replace('.parquet', f'_{price}_{year}.parquet'))\n",
    "#         del df\n",
    "\n",
    "#         #     result_dfs.append(df)\n",
    "\n",
    "#         # # Concatenate results for this price across all years\n",
    "#         # full_df = pd.concat(result_dfs)\n",
    "        \n",
    "#         # print(f\"saved to {content.replace('processed', 'data_prep').replace('.parquet', f'_{price}.parquet')}\")\n",
    "#             # del df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
