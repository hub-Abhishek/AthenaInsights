{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb12f7bf-cb8b-4aec-a0f9-35ea35e6e168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install protobuf==3.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d70c5-97d1-4580-8f7f-460ead35b1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.xgboost.estimator import XGBoost\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587763c-713e-4db8-a201-5c74ca9dd3c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### data + dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d675d-d1be-4523-9df9-b3d11f1691a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://sisyphus-general-bucket/AthenaInsights/latest_data/model/data/stock_bars_1min.parquet' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6efc1-2794-4f0b-ae59-f1d1b71e6d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_map = {'A': 0, 'B': 1, 'C':2}\n",
    "reverse_category_map = {v: k for k, v in category_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a751387-d970-48a4-a286-ee3047580583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "df['mapped_category'] = df['category'].map({'A': 0, 'B': 1, 'C':2})\n",
    "df['mapped_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba38804-027d-4c73-9ffe-e47af1ea0b7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f540a-69fc-48d5-9381-cf29cc29358e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609896b-914f-4a8c-8fb5-7085b4c0160d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = '2024-10-01'\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "date_series = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "print(date_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a1027-3d21-48f4-8b87-26d3cf9b858e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with initial content\n",
    "file_name = \"results_0.xlsx\"\n",
    "\n",
    "# if os.path.exists(file_name):\n",
    "#     file_name, result_num = file_name.split(\".\")[0].split(\"_\")\n",
    "#     result_num += 1\n",
    "#     file_name = file_name + result_num + \".xlsx\"\n",
    "#     print(f'base name: {file_name}')\n",
    "\n",
    "data = {'features used': list(df.columns)}\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "sheet_name = 'InitialSheet'\n",
    "\n",
    "# Write the DataFrame to an Excel file with a custom sheet name\n",
    "with pd.ExcelWriter(file_name, engine='openpyxl') as writer:\n",
    "    data.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f59c55-94d4-4138-a3f7-b90a18036535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dates(dt):\n",
    "    test_date = dt\n",
    "    next_day = (datetime.strptime(test_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    next_10_day = (datetime.strptime(test_date, '%Y-%m-%d') + timedelta(days=9)).strftime('%Y-%m-%d')\n",
    "    prev_day = (datetime.strptime(test_date, '%Y-%m-%d') + timedelta(days=-1)).strftime('%Y-%m-%d')\n",
    "    return test_date, next_day, next_10_day, prev_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0525ac-301b-42e7-9dea-80f6bc6420cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(dt):\n",
    "\n",
    "    X_train = df.loc[:prev_day, ].drop(columns=['category', 'mapped_category'])\n",
    "    y_train = df.loc[:prev_day, 'mapped_category']\n",
    "\n",
    "    X_test = df.loc[test_date: next_10_day, ].drop(columns=['category', 'mapped_category'])\n",
    "    y_test = df.loc[test_date: next_10_day, 'mapped_category']\n",
    "\n",
    "    X_test_full = df.loc[test_date:, ].drop(columns=['category', 'mapped_category'])\n",
    "    y_test_full = df.loc[test_date:, 'mapped_category']\n",
    "\n",
    "    X_test_only_next_day = df.loc[test_date, ].drop(columns=['category', 'mapped_category'])\n",
    "    y_test_only_next_day = df.loc[test_date, 'mapped_category']\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, X_test_full, y_test_full, X_test_only_next_day, y_test_only_next_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a89bcf5-f1b0-428e-bb57-50e218fe00ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log(x, dt, image=None, add=None):\n",
    "    if type(x)==type('str'):\n",
    "        data = {'text': [x]}\n",
    "        data = pd.DataFrame(data)\n",
    "\n",
    "        book = openpyxl.load_workbook(file_name)\n",
    "        if dt in book.sheetnames:\n",
    "            sheet = book[dt]\n",
    "            start_row = sheet.max_row + 1  # Find the first empty row\n",
    "        else:\n",
    "            sheet = book.create_sheet(dt)  # Create a new sheet\n",
    "            start_row = 1\n",
    "\n",
    "         # Convert DataFrame to rows and append to the sheet\n",
    "        for r_idx, row in enumerate(dataframe_to_rows(data, index=False, header=False), start=start_row):\n",
    "            for c_idx, value in enumerate(row, start=1):\n",
    "                sheet.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "        book.save(file_name)\n",
    "    \n",
    "    elif image==1:\n",
    "        workbook = xlsxwriter.Workbook(file_name)\n",
    "        worksheet = workbook.get_worksheet_by_name(dt)\n",
    "        start_row = openpyxl.load_workbook(file_name)[dt].max_row + 1\n",
    "        worksheet.insert_image(f\"B{start_row}\", add)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6373b-0ad4-472d-a627-08d022fba66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialte_and_train(X_train, y_train, X_test, y_test, X_test_full, y_test_full, X_test_only_next_day, y_test_only_next_day):\n",
    "    \n",
    "    clf = xgb.XGBClassifier(n_estimators=100,\n",
    "                            objective='multi:softmax',\n",
    "                            n_jobs =-1,\n",
    "                            random_state=420,\n",
    "                            num_class=3,\n",
    "                            eval_metric=['merror','mlogloss'])\n",
    "    clf.fit(X_train,\n",
    "            y_train,\n",
    "            verbose=1,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test), (X_test_full, y_test_full), (X_test_only_next_day, y_test_only_next_day)])\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622eb479-b79d-4716-911c-81361a7aad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(clf, dt):\n",
    "    results = clf.evals_result()\n",
    "    epochs = len(results['validation_0']['mlogloss'])\n",
    "    x_axis = range(0, epochs)\n",
    "\n",
    "    log(f\"results: {results}\", dt)\n",
    "    log(f\"epochs: {epochs}\", dt)\n",
    "    log(\"\\n\\n\", dt)\n",
    "\n",
    "    # xgboost 'mlogloss' plot\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    ax.plot(x_axis, results['validation_0']['mlogloss'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['mlogloss'], label='Test')\n",
    "    ax.plot(x_axis, results['validation_2']['mlogloss'], label='Test_full')\n",
    "    ax.plot(x_axis, results['validation_3']['mlogloss'], label='Test_only_next_day')\n",
    "    ax.legend()\n",
    "    plt.ylabel('mlogloss')\n",
    "    plt.title(f'GridSearchCV XGBoost mlogloss - {dt}')\n",
    "    plt.show()\n",
    "    fig.savefig(f'GridSearchCV XGBoost mlogloss - {dt}.png')\n",
    "    log(None, dt, image=1, add=f'GridSearchCV XGBoost mlogloss - {dt}.png')\n",
    "    log(\"\\n\\n\", dt)\n",
    "\n",
    "    # xgboost 'merror' plot\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    ax.plot(x_axis, results['validation_0']['merror'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['merror'], label='Test')\n",
    "    ax.plot(x_axis, results['validation_2']['merror'], label='Test_full')\n",
    "    ax.plot(x_axis, results['validation_3']['merror'], label='Test_only_next_day')\n",
    "    ax.legend()\n",
    "    plt.ylabel('merror')\n",
    "    plt.title(f'GridSearchCV XGBoost merror - {dt}')\n",
    "    plt.show()\n",
    "    fig.savefig(f'GridSearchCV XGBoost merror - {dt}.png')\n",
    "    log(None, dt, image=1, add=f'GridSearchCV XGBoost merror - {dt}.png')\n",
    "    log(\"\\n\\n\", dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e4224-14bb-4152-896b-dd8c7e7a320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reports(X_test, y_test, clf):\n",
    "    log('## ---------- Model Classification Report ----------', dt)\n",
    "    log('## get predictions and create model quality report', dt)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    log('\\n------------------ Confusion Matrix -----------------\\n', dt)\n",
    "    log(confusion_matrix(y_test, y_pred), dt)\n",
    "    preds_probs = clf.predict_proba(X_test)\n",
    "\n",
    "    for i in range(4, 10, 1):\n",
    "        log(f'threshold - {i/10}', dt)\n",
    "        preds_probs1 = (preds_probs>=i/10).argmax(axis=1,)\n",
    "        log(confusion_matrix(y_test_only_next_day, preds_probs1), dt)\n",
    "        log('\\n\\n', dt)\n",
    "\n",
    "    log('\\n-------------------- Key Metrics --------------------', dt)\n",
    "    log('\\nAccuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)), dt)\n",
    "    log('Balanced Accuracy: {:.2f}\\n'.format(balanced_accuracy_score(y_test, y_pred)), dt)\n",
    "\n",
    "    log('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')), dt)\n",
    "    log('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')), dt)\n",
    "    log('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')), dt)\n",
    "\n",
    "    log('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')), dt)\n",
    "    log('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')), dt)\n",
    "    log('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')), dt)\n",
    "\n",
    "    log('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')), dt)\n",
    "    log('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')), dt)\n",
    "    log('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')), dt)\n",
    "\n",
    "    log('\\n--------------- Classification Report ---------------\\n', dt)\n",
    "    log(classification_report(y_test, y_pred), dt)\n",
    "    log('---------------------- XGBoost ----------------------', dt) # unnecessary fancy styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05deb80d-0379-4d18-bbd4-be501d58d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorization(df, date, pred, field='close', ):\n",
    "    \"\"\" Plot categorization for a given day with dynamic field selection \"\"\"\n",
    "    df_day = df.loc[date]\n",
    "    df_day['preds'] = list(pred)\n",
    "    # categories, future_highs, future_lows = categorize_points(df_day, field=field, **kwargs)\n",
    "    # df_day['category'] = categories\n",
    "    # df_day['future_highs'] = future_highs\n",
    "    # df_day['future_lows'] = future_lows\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(df_day.index, df_day[field], label=f'{field.capitalize()} Price', color='gray', linewidth=2)\n",
    "    # plt.plot(df_day.index, df_day['close'], label=f'{field.capitalize()} Price', color='blue', linewidth=1)\n",
    "    for cat, color in zip(['A', 'B', 'C'], ['green', 'red', 'gray']):\n",
    "        plt.scatter(df_day[df_day['category'] == cat].index, df_day[df_day['category'] == cat][field], color=color, label=f'Category {cat}', s=30 if cat!='C' else 0)\n",
    "    for cat, color in zip(['A', 'B', 'C'], ['blue', 'black', 'pink']):\n",
    "        print(cat)\n",
    "        print(df_day[df_day['preds'] == cat].index)\n",
    "        plt.scatter(df_day[df_day['preds'] == cat].index, df_day[df_day['preds'] == cat][field], color=color, label=f'Preds {cat}', s=20 if cat!='C' else 10, \n",
    "                    # marker = '1' if cat=='B' else '2' if cat=='A' else '+')\n",
    "                    marker='s')\n",
    "    plt.legend()\n",
    "    plt.title(f'Price Categorization on {date}')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel(f'{field.capitalize()} Price')\n",
    "    plt.show()\n",
    "    plt.savefig(f'plot for day - {date}.png')\n",
    "    log(None, dt, image=1, add=f'plot for day - {date}.png')\n",
    "    log(\"\\n\\n\", date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d619bc-a1cf-4306-b501-0cd1fa04f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt in date_series:\n",
    "    log(f\"running for dt = {dt}\", dt)\n",
    "    log (\"\\n\\n\", dt)\n",
    "    test_date, next_day, next_10_day, prev_day = get_dates(dt)\n",
    "    \n",
    "    log(f\"test_date: {test_date}, next_day: {next_day}, next_10_day: {next_10_day}, prev_day: {prev_day}\", dt)\n",
    "    log (\"\\n\", dt)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test, X_test_full, y_test_full, X_test_only_next_day, y_test_only_next_day = train_test_split(dt)\n",
    "    \n",
    "    log(f\"y_train.value_counts():\\n{log(y_train.value_counts())}\", dt)\n",
    "    log(f\"y_test.value_counts():\\n{y_test.value_counts()}\", dt)\n",
    "    log(f\"y_test_full.value_counts():\\n{y_test_full.value_counts()}\", dt)\n",
    "    log(f\"y_test_only_next_day.value_counts():\\n{y_test_only_next_day.value_counts()}\", dt)\n",
    "    log (\"\\n\\n\", dt)\n",
    "    \n",
    "    log(\"training the model\", dt)\n",
    "    clf = initialte_and_train(X_train, y_train, X_test, y_test, X_test_full, y_test_full, X_test_only_next_day, y_test_only_next_day)\n",
    "    log (\"\\n\\n\", dt)\n",
    "    \n",
    "    log(\"results\", dt)\n",
    "    get_results(clf, dt)\n",
    "    log (\"\\n\\n\", dt)\n",
    "    \n",
    "    log(\"reports\", dt)\n",
    "    \n",
    "    log(\"10 day test\", dt)\n",
    "    generate_reports(X_test, y_test, clf)\n",
    "    log (\"\\n\\n\", dt)\n",
    "    \n",
    "    log(\"full day test\", dt)\n",
    "    generate_reports(X_test_full, y_test_full, clf)\n",
    "    log (\"\\n\\n\", dt)\n",
    "    \n",
    "    log(\"1 day test\", dt)\n",
    "    generate_reports(X_test_only_next_day, y_test_only_next_day, y_pred, clf)\n",
    "    log (\"\\n\\n\", dt)\n",
    "    \n",
    "    feature_important = clf.feature_importances_ \n",
    "    keys = list(X_train.columns)\n",
    "    values = list(feature_important)\n",
    "\n",
    "    log(\"feature importances\", dt)\n",
    "    fea_imp = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=True)\n",
    "    log(fea_imp, dt)\n",
    "    \n",
    "    preds_probs = clf.predict_proba(X_test_only_next_day)\n",
    "    preds_probs1 = (preds_probs>=0.5).argmax(axis=1,)\n",
    "    plot_categorization(df, dt, pd.Series(preds_probs1).map(reverse_category_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42de468-9b77-4dc2-b1c3-434dde867a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_test.value_counts() # category # 2    6809 # 0     523 # 1     348\n",
    "# 134 + 0 + 389 # 0\n",
    "# 0 + 24 + 324 # 1\n",
    "# 68 + 34 + 6707 # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa671d3f-84a0-4ac2-84c4-a916718c0819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca1ddf5-8e1b-407e-8c3f-21cab674a041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_fools_gold",
   "language": "python",
   "name": "conda_fools_gold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
