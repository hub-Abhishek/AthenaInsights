{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb12f7bf-cb8b-4aec-a0f9-35ea35e6e168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.1\n",
      "  Downloading protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (698 bytes)\n",
      "Downloading protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.28.2\n",
      "    Uninstalling protobuf-5.28.2:\n",
      "      Successfully uninstalled protobuf-5.28.2\n",
      "Successfully installed protobuf-3.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1d70c5-97d1-4580-8f7f-460ead35b1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.xgboost.estimator import XGBoost\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a1dfc4-e19a-48b4-86ef-747d0d68959b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_date = '2024-10-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "083d675d-d1be-4523-9df9-b3d11f1691a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19943/2817742588.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('s3://sisyphus-general-bucket/AthenaInsights/latest_data/model/data/stock_bars_1min.parquet' )\n",
    "\n",
    "df = df.fillna(0)\n",
    "train_X = df.loc[:test_date, ].drop(columns='category')\n",
    "train_y = df.loc[:test_date, 'category'] # ['category']\n",
    "\n",
    "test_X = df.loc[test_date:, ].drop(columns='category')\n",
    "test_y = df.loc[test_date:, 'category'] # ['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe62d38-a2e3-45f9-84a7-440941234d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=train_X, label=train_y)\n",
    "dtest = xgb.DMatrix(data=test_X, label=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f73e43-b4cb-4e6e-a1e9-19417b6027e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "clf = xgboost.XGBClassifier(n_estimators=100, objective='multi:softmax', n_jobs =-1, random_state=420, )\n",
    "clf.fit(train_X, train_y\n",
    "# bst = xgb.train(params, dtrain, num_boost_round, evals=[(dtest, 'test')], early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bf7b535-b436-4c1d-bc24-5eedbc44df59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m num_boost_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m(params, dtrain, num_boost_round, evals\u001b[38;5;241m=\u001b[39m[(dtest, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)], early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(data=train_X, label=train_y)\n",
    "dtest = xgb.DMatrix(data=test_X, label=test_y)\n",
    "\n",
    "# Parameters for XGBoost\n",
    "# params = os.environ['hyperparameters']\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "}\n",
    "num_boost_round = 100\n",
    "\n",
    "# Training the model\n",
    "bst = xgb.train(params, dtrain, num_boost_round, evals=[(dtest, 'test')], early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6865e45f-2d77-4c58-98dd-113d185faaa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dval \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_val)\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(dval)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "dval = xgb.DMatrix(X_val)\n",
    "predictions = bst.predict_proba(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f15621ae-2023-4093-8a45-cddb9e1da8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "923a9100-aaea-40d4-a39b-03c08e3425b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd1d0c-2e9d-4ab9-ae05-45e0c66d60bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_fools_gold",
   "language": "python",
   "name": "conda_fools_gold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
